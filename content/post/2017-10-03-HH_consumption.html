---
title: "Final consumption expenditure of households"
author: "Simona Jokubauskaite"
date: 2017-10-03T21:07:14-05:00
categories: ["gganimate"]
tags: ["R", "eurostat", "gganimate", "cowplot", "TheEconomist"]
thumbnailImagePosition: left
thumbnailImage: http://is2.mzstatic.com/image/thumb/Purple41/v4/a2/b9/5f/a2b95fc3-2db7-827d-870a-e99dbb696434/source/1200x630bb.jpg
coverImage: ./FOTO.jpg
metaAlignment: center
disable_comments: true
output:
  blogdown::html_page:
    toc: false
    css: "/css/my-style.css"
--- 

  <link rel="stylesheet" href="/css/my-style.css" type="text/css" />


<p>In 2015 I was working on my master thesis “<a href="https://www.researchgate.net/publication/309557441_The_integration_of_QUAIDS_and_input-output_analysis_in_a_panel_data_setting">The integration of (QU)AIDS and input-output analysis in a panel data setting</a>” and had to analyse the structure of household expenditure. I stumbled open several visualizations in <a href="http://www.economist.com/blogs">The Economist</a> (<a href="http://www.economist.com/blogs/graphicdetail/2015/09/daily-chart-9?fsrc=scn/fb/te/bl/ed/howcountriesspendtheirmoney">World</a> and <a href="http://www.economist.com/blogs/graphicdetail/2015/09/daily-chart-12">EU</a>) while searching for information on this topic. Thinking that they looked great I wanted to replicate these with R. The way I chose to do it is based on the question in <a href="http://stackoverflow.com/questions/15840926/categorical-bubble-plot-for-mapping-studies">stackoverflow</a>.</p>
<p>At first we will download two Eurostat data sets:</p>
<ul>
<li>nama_co3_c - Final consumption expenditure of households by consumption purpose - COICOP 3 digit - aggregates at current prices, ESA 1995.</li>
<li>nama_10_co3_p3 - Final consumption expenditure of households by consumption purpose (COICOP 3 digit) ESA 2010.</li>
</ul>
<ol style="list-style-type: decimal">
<li>Load libraries:</li>
</ol>
<pre class="r"><code>library(eurostat)
library(data.table)
library(tidyr)
library(magrittr)
library(ggplot2)
library(cowplot)
library(plyr)
library(dplyr)
library(gganimate)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Download the data:</li>
</ol>
<pre class="r"><code>data &lt;- lapply(c(&quot;nama_co3_c&quot;, &quot;nama_10_co3_p3&quot;), get_eurostat)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Combine available information. The new European System of National and Regional Accounts (ESA10) was introduced in 2014 (previous one is named ESA95). As not all the data has been converted to ESA10 and I wanted to get the maximal amount of information, I combined both data sets:</li>
</ol>
<pre class="r"><code>#ESA95
esa95 &lt;- data.table(data[[1]])
esa95%&lt;&gt;%filter(unit%in%c(&quot;MIO_EUR&quot;)&amp;(nchar(as.character(coicop))==4|coicop%in%&quot;TOTAL&quot;))%&gt;%data.table
#ESA10
esa10 &lt;- data.table(data[[2]])
esa10%&lt;&gt;%filter(unit%in%c(&quot;CP_MEUR&quot;)&amp;(nchar(as.character(coicop))==4|coicop%in%&quot;TOTAL&quot;))%&gt;%data.table
esa10[, unit:=&quot;MIO_EUR&quot;]
setnames(esa10, &quot;values&quot;, &quot;esa10&quot;)
setnames(esa95, &quot;values&quot;, &quot;esa95&quot;)

dat &lt;- merge(esa95, esa10, all=TRUE, by=intersect(names(esa95),names(esa10)))
dat[, year:=time%&gt;%gsub(&quot;-.*&quot;, &quot;&quot;, .)%&gt;%as.numeric]
dat%&lt;&gt;%filter(year&gt;1994&amp;year&lt;2016)%&gt;%filter(!grepl(&quot;^EA|EU1|EU27&quot;, geo))%&gt;%filter(!geo%in%c(&quot;JP&quot;, &quot;US&quot;))%&gt;%data.table</code></pre>
<p>For some countries only ESA95 was available, so it was used to calculate the final consumption shares.</p>
<pre class="r"><code>#only one classification is available
only1 &lt;- dat[,lapply(.SD, function(x)any(!is.na(x))), by=geo, .SDcols=c(&quot;esa95&quot;, &quot;esa10&quot;)]
tmp &lt;- only1[esa95==TRUE&amp;esa10==FALSE, geo]
dat[geo%in%tmp, esa10:=esa95]

dt &lt;- dat[coicop!=&quot;TOTAL&quot;, lapply(.SD, function(x)sum(x, na.rm=TRUE)), by=.(geo, year), .SDcols=c(&quot;esa95&quot;, &quot;esa10&quot;)]
setnames(dt, c(&quot;esa95&quot;, &quot;esa10&quot;), c(&quot;s95&quot;, &quot;s10&quot;))
dat &lt;- merge(dat[coicop!=&quot;TOTAL&quot;], dt, intersect(names(dat), names(dt)),all=TRUE)
dat &lt;- dat[!is.na(time)]
setnames(dat, c(&quot;esa95&quot;, &quot;esa10&quot;), c(&quot;v95&quot;, &quot;v10&quot;))
dat[, esa95:=v95/s95]
dat[, esa10:=v10/s10]
dat &lt;- dat[order(geo, coicop, year)]</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Extrapolating shares for missing ESA10 entries:</li>
</ol>
<pre class="r"><code>fill_miss_dat &lt;- function(datnd){
  datno &lt;- datnd
  datnd &lt;- data.table(datnd)
  datnd[,new:=esa10]
  datnd &lt;- datnd[order(geo,coicop,year)]
  #print(paste(unique(datnd[,geo]),unique(datnd[,coicop])))
  datnd[, index:=sum(all(is.na(esa10)))]
  datnd &lt;- datnd[index!=1, ]
  if(dim(datnd)[1]!=0){
    datnd[,index:=NULL]
    while(sum(is.na(datnd[,new]))&gt;0){
      datnd[, lag := shift(esa95, type=&#39;lag&#39;,n = 1)]
      datnd[, lead := shift(esa95, type=&#39;lead&#39;,n = 1)]
      datnd[, lagn := shift(new, type=&#39;lag&#39;,n = 1)]
      datnd[, leadn := shift(new, type=&#39;lead&#39;,n = 1)]
      datnd[,n1:=(esa95/lead)*leadn]
      datnd[,n2:=(esa95/lag)*lagn]
      datnd[is.na(new),new:=mean(c(n1,n2),na.rm=TRUE),by=year]
    }
      datnd[,c(&quot;lag&quot;, &quot;lead&quot;,&quot;lagn&quot;, &quot;leadn&quot;, &quot;n1&quot;,&quot;n2&quot;):=NULL]
  }else{
    datnd&lt;-datno
  }
  datnd
}

res &lt;- ddply(dat, .(geo, coicop), fill_miss_dat)
res &lt;- data.table(res)
res &lt;- res[, .(geo, coicop, year, new)]
#renorm
res[, new:=new/sum(new)*100, by=.(geo,year)]
setnames(res, &quot;new&quot;, &quot;prc&quot;)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Building groups (NMS11 (new member states), WB (Western Balkan)), data preparation for drawing:</li>
</ol>
<pre class="r"><code>eu28 &lt;- res[geo%in%&quot;EU28&quot;]
eu28 &lt;- eu28[,.(year, coicop, prc)]
setnames(eu28,&quot;prc&quot;,&quot;eu28&quot;)
dat &lt;- merge(res, eu28, all=TRUE, by=intersect(names(res),names(eu28)))
eul &lt;-unique(dat[,geo])

nms11 &lt;- c(&quot;BG&quot;,&quot;HR&quot;,&quot;CZ&quot;,&quot;EE&quot;,&quot;HU&quot;,&quot;LV&quot;,&quot;LT&quot;,&quot;PL&quot;,&quot;RO&quot;,&quot;SI&quot;,&quot;SK&quot;)
wb &lt;- c(&quot;AL&quot;,&quot;BA&quot;,&quot;XK&quot;,&quot;ME&quot;,&quot;MK&quot;, &quot;RS&quot;)
nms11 &lt;- nms11[nms11%in%eul]
wb &lt;- wb[wb%in%eul]
other &lt;- eul[!eul%in%c(nms11,wb,&quot;EU28&quot;)]%&gt;%as.character

geo1 &lt;- data.table(geo=c(&quot;EU28&quot;, nms11, wb, other),geo1=1:length(eul))
nmsx &lt;- mean(c(max(geo1[geo%in%nms11,geo1]), min(geo1[geo%in%wb,geo1])))
wbx &lt;- mean(c(max(geo1[geo%in%wb,geo1]), min(geo1[geo%in%other,geo1])))

dat%&lt;&gt;%filter(geo%in%eul)%&gt;%data.table
dat[, index:=&quot;&quot;]
dat[, minspend:=min(prc),by=.(year,coicop)]
dat[, maxspend:=max(prc),by=.(year,coicop)]
dat[prc==minspend, index:=&quot;minspend&quot;]
dat[prc==maxspend, index:=&quot;maxspend&quot;]
dat[prc&gt;=eu28&amp;index==&quot;&quot;, index:=&quot;above&quot;]
dat[prc&lt;eu28&amp;index==&quot;&quot;, index:=&quot;below&quot;]
dat[index%in%c(&quot;minspend&quot;,&quot;maxspend&quot;),labels:=round(prc,1)]
dat[,radius:=sqrt(prc/pi)]

dat &lt;- merge(dat,geo1, all=TRUE, by=&quot;geo&quot;)
coicop1 &lt;- data.table(coicop=unique(dat[,coicop]),coicop1=1:length(unique(dat[,coicop])))
dat &lt;- merge(dat,coicop1, all=TRUE, by=&quot;coicop&quot;)

dat[,col:=ifelse(index%in%c(&quot;maxspend&quot;,&quot;above&quot;),&quot;orangered&quot;,&quot;royalblue1&quot;)]
dat[,col1:=ifelse(index%in%c(&quot;maxspend&quot;),&quot;orangered4&quot;,ifelse(index%in%c(&quot;minspend&quot;),&quot;royalblue4&quot;,col))]
dat[!is.na(labels),col5:=factor(ifelse(col1%in%&quot;royalblue4&quot;,&quot;black&quot;,&quot;white&quot;))]
dat[,rect_st:=coicop1-sqrt(eu28/pi)/6, by=year]
dat[,rect_en:=coicop1+sqrt(eu28/pi)/6, by=year]


dic1 &lt;- data.table(coicop=dat[, coicop]%&gt;%as.character%&gt;%sort%&gt;%unique, name=c(&#39;Food&#39;, &#39;Alcohol &amp; tabacco&#39;, &#39;Clothing &amp; footware&#39;, &#39;Housing&#39;, &#39;Furnishings&#39;, &#39;Health&#39;, &#39;Transport&#39;, &#39;Commun.&#39;, &#39;Recreation&#39;, &#39;Education&#39;, &#39;Restaurants &amp; hotels&#39;, &#39;Other&#39;))
dat &lt;- merge(dat, dic1,all.x=TRUE, by=&quot;coicop&quot;)
coicop1 &lt;- merge(coicop1,dic1, all=TRUE, by=&quot;coicop&quot; )

dat[, size1:=radius*6,by=year]
dat[, size2:=radius*5,by=year]

c1 &lt;-c(&quot;orangered&quot;,&quot;orangered4&quot;,&quot;royalblue1&quot;,&quot;royalblue4&quot;)
c0 &lt;-c(&quot;orangered&quot;,&quot;royalblue1&quot;)
c2 &lt;-c(&quot;orangered&quot;,&quot;orangered&quot;,&quot;royalblue1&quot;,&quot;royalblue1&quot;)
lab &lt;- c(&quot;above EU28&quot;,&quot;highest spend&quot;,&quot;below EU28&quot;, &quot;lowest spend&quot;)</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Drawing:</li>
</ol>
<pre class="r"><code>q &lt;- ggplot(dat, aes(x=geo1, y=coicop1, frame=year))
q &lt;- q + geom_rect(aes(ymin = rect_st, ymax = rect_en, xmin = -Inf, xmax = Inf, frame=year), alpha = .1, fill=&quot;#b8d2fc&quot;, color=NA)
q &lt;- q + geom_vline(xintercept = nmsx, colour=&quot;red&quot;)+geom_vline(xintercept = wbx, colour=&quot;red&quot;)
q &lt;- q + geom_point(aes(size=size1,colour=factor(col1),fill=factor(col), frame=year),shape=21,stroke =2)
q &lt;- q + geom_text(aes(label=labels, frame=year),size=4, color=&quot;white&quot;)
q &lt;- q + scale_x_continuous(expand=c(0, 0), limits=c(1, 35.7), breaks = geo1[,geo1], labels = geo1[,geo])+
  scale_y_continuous(breaks = coicop1[,coicop1] , labels = coicop1[,name])
q &lt;- q + scale_size_identity()+xlab(&quot;&quot;)+ylab(&quot;&quot;)+labs(caption = &quot;Source: Eurostat&quot;)
q &lt;- q + scale_color_manual(name=&quot;&quot;, values = c1 ,labels =lab )+
  scale_fill_manual(guide=&quot;none&quot;,values=c0)+guides(color=guide_legend(override.aes=list(fill=c2)))
q &lt;- q + theme_bw() + theme(legend.position = &quot;top&quot;,plot.title = element_text(hjust = 0.5),
                            text = element_text(size=29),
                            legend.key = element_rect(colour = &quot;white&quot;),
                            panel.grid.major.y=element_blank(),
                            panel.grid.minor.y=element_blank(), 
                            panel.grid.minor.x=element_blank(),
                            panel.grid.major.x = element_line( size=.1, color=&quot;grey&quot; ),
                            axis.line.x = element_line(color = &quot;white&quot;,linetype = &quot;solid&quot;),
                            axis.line.y = element_line(color = &quot;white&quot;,linetype = &quot;solid&quot;),
                            axis.ticks.x =element_line(color = &quot;white&quot;,linetype = &quot;solid&quot;),
                            axis.ticks.y =element_line(color = &quot;white&quot;,linetype = &quot;solid&quot;))

gganimate(q, file=&quot;HH_gif.gif&quot;, ani.width=1800, ani.height=720)</code></pre>
<p><img src="/content/post/HH_gif.gif" alt="Bubble Chart" style="width:1800px;height:300px;"></p>
<p>One can clearly see that expenditure on food makes out the biggest share in NMS and WB, whereas old member states spend more on housing. From this perspective WB is similar to NMS. Luxembourg(LU) has extremely high share of alcohol and tobacco consumption. “This does not imply that the households are heavy drinkers, it is more a sign of a huge gap between purchases done by residents and tourists, for more information on this problem see <a href="http://dx.doi.org/10.1787/factbook-2013-99-en">OECD</a>”<a href="https://www.researchgate.net/publication/309557441_The_integration_of_QUAIDS_and_input-output_analysis_in_a_panel_data_setting">[1]</a>.</p>
